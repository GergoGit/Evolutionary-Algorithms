\documentclass[border=0.2cm]{report}
 
% Required packages
\usepackage{tikz}
\usetikzlibrary{shapes,positioning}
\usepackage{hyperref} % for url link
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=blue,
}
\usepackage[norelsize, ruled, lined, boxed, commentsnumbered]{algorithm2e}
\usepackage{physics} % for gradient
\usepackage{optidef} % equation number
\usepackage{bm} % for bold fonts

\usepackage{amsfonts} % contains \mathbb{R}
\newcommand{\R}{\mathbb{R}} % create command \R from \mathbb{R}
 
\title{Evolutionary Algorithms (EA)}
\author{Gergő Bonnyai}
\date{\today}

\begin{document}
\maketitle

\tableofcontents
\listoffigures

\clearpage

\chapter{Differential Evolution (DE)}
\section{Story}

Differential Evolution (DE) \cite{de1} is an efficient and powerful
population-based stochastic search technique for solving global optimization problems. 

\section{Pseudo code}
\section{Flowchart}

\chapter{Evolutionary Strategy (ES)}
\section{Story}

Evolution (or evolutionary) strategy (ES) \cite{es1, es2} is a search paradigm inspired by biological evolution. ES implenenting a repeated process of stochastically generating new solution candidates from the actual set of solutions. More precisely in every generation (iteration) the individuals (actual solutions) of the population alone or by forming pairs generate offsprings (new candidates). The fitness of the offsprings are evaluated and the best ones will become the parents for the next generation. There are many variants of evolution strategy. These varians work with different (fitness-based and fitness-independent) mating and recombination strategies. Here I outline a simpler, but most frequently used version where every member of the population on their own generate multiple offsprings. I refer to this process as mutation. At the end of every generation it can be decided to apply elitism where we can keep the best parents in the next generation or not. \\

\noindent
Let $X=\{x_1,x_2,\ldots,x_N\}$ population of individuals, where $N$ is the population size and $x_i \in \R^D$.
$f: \R^{D}\to\R^1$ is the fitness function and $fitness_i=f(x_i)$ is the fitness value of $x_i$. Mutation parameter $\sigma$ controls the random offspring generation process.\\
\noindent
Offsprings are generated using the following formula: \\
\begin{equation}\label{eqn_es_generate_offspring}
z_{ij}=x_i(t)+rand_j*\sigma(t)
\end{equation}
Where $rand_{j} \in N(0, 1)$, where $N$ stands for normal (Gauss) distribution. \\ 
We apply a $\delta$ decay parameter on $\sigma$ to gradually decrease the distance between the parent $x_i$ and the created offspring $z_{ij}$ by generations using the following equation:\\
\begin{equation}\label{eqn_es_sigma_decay}
\sigma(t+1)=\sigma(t)*\delta
\end{equation}
$\delta$ parameter is responsible for the transition between exploration and exploitation phases.

\section{Pseudo code}

\begin{algorithm}[H]
\caption{Evolutionary Strategy}
 
 \Begin{
 Set $N$: population size, $T$: number of iterations, $k$: number of offsprings, $\sigma$: mutation parameter, $\delta$: decay parameter for $\sigma$ \\
 Initialize random population of individuals $X=\{x_1,x_2,\ldots,x_N\}$, \\
 Calculate fitness values $fitness_i$ for $i \in
 \{1,2,...,N\}$\\
 \While{$t\leq T$ or Stopping criteria not met}{
  \For{$i \gets 1 \textrm{ to } N$}{
  	  \For{$j \gets 1 \textrm{ to } k$}{
  	  	 Create offspring $z_{ij}$ by Equation \ref{eqn_es_generate_offspring} \\
         Check search space \\
         Calculate fitness value $fitness_{ij}$\\
         \If{$fitness_{ij}<fitness_{best}$}{
           $x_{best}=z_{ij}$ \\
           $fitness_{best}=fitness_{ij}$ \\
           }	  
  	  }
    }
    \If{apply elitism}{
  	  	Create a new population keeping the best $N$ individuals including parents and offsprings based on fitness values. \\
  	  	}
  	\Else{
  	  	Create a new population keeping the best $N$ offsprings based on fitness values. \\
  	  	}
    Check Stopping Criteria \\
    Decrease the value of $\sigma$ by Equation \ref{eqn_es_sigma_decay}\\
    $t=t+1$
 }
 }
\end{algorithm}

\section{Flowchart}

\chapter{Cuckoo Search (CS)}
\section{Story}
Cuckoo Search (CS) \cite{cs1} is a metaheuristic algorithm based on the obligate brood parasitic behaviour of some cuckoo species. Cuckoos are birds with an agressive reproduction strategy.  Some cockoo species lay their eggs in communal nests, though they may remove others’ eggs to increase the hatching probability of their own eggs. Some other cockoo species lay their eggs in the nests of other host birds. Some host birds can engage direct conflict with the intruding cuckoos. Or if a host bird discovers the eggs are not their owns, they will either throw these alien eggs away or simply abandon it's nest and build a new nest elsewhere.
In the algorithm in each host nest there is one egg representing a solution. By iterations every cuckoo lays one egg and dumps it's egg in a randomly chosen nest, where a cuckoo egg appears as a new solution. If the new solution is a better one, than it is replaced by the original egg. The best nests will continue in the next iteration. However a given proportion of cuckoo eggs are discovered by the host bird (worst nests) and the host bird throw the egg away/abandon the nest, and build a new nest (new solution) somewhere else. Cuckoo eggs (new solutions) are generated with Lévy flights as researchers found it more efficient in the exploration phase. \\

\noindent
Let $X=\{x_1,x_2,\ldots,x_N\}$ population of host nests, where $N$ is the population size and $x_i \in \R^D$.
$f: \R^{D}\to\R^1$ is the fitness function and $fitness_i=f(x_i)$ is the fitness value of $x_i$.\\
New cuckoo egg is created by Lévy flight with the following formula:
\begin{equation}\label{eqn_cs_levyflight}
z_i=x_l(t)+rand_i*(x_m-x_n)
\end{equation}
where $rand_i \in$ Lévy($\lambda$), and $x_l, x_m, x_n$ are randomly chosen host nests. \\ 

\section{Pseudo code}

\begin{algorithm}[H]
\caption{Cuckoo Search}
 
 \Begin{
 Set $N$: population size, $T$: number of iterations, $k$: number of cuckoos, $\rho$: proportion of abandoned nests \\
 Initialize random population of host nests $X=\{x_1,x_2,\ldots,x_N\}$, \\
 Calculate fitness values $fitness_i$ for $i \in
 \{1,2,...,N\}$\\
 \While{$t\leq T$ or Stopping criteria not met}{
  \For{$i \gets 1 \textrm{ to } k$}{
    Create cuckoo $z_i$ by Equation \ref{eqn_cs_levyflight} \\
    Check search space \\
    Calculate fitness value $fitness_{z_i}$\\
    Choose a random host nest $x_j$ \\
    \If{$fitness_{z_i}<fitness_j$}{
      $x_j=z_i$ \\
      $fitness_j=fitness_{z_i}$ \\
      }
    }
    Leave $\rho$ proportion of worst nests and create new random ones. \\
    Calculate fitness values of newly created host nests. \\
    Determine $x_{best}$ and $fitness_{best}$. \\
    Check Stopping Criteria \\
    $t=t+1$
 }
 }
\end{algorithm}

\section{Flowchart}

\chapter{Artificial Bee Colony (ABC)}
\section{Story}
Artificial Bee Colony (ABC) \cite{abc1} algorithm is a swarm based metaheuristic algorithm inspired by the foraging behavior of honey bees. The essential components of the algorithm are the food sources, employed and unemployed foraging bees. The colony of bees is looking for the best food sources. First the bees randomly discover a set of random food sources (population). Then iteratively search for better sources (solutions) applying a special strategy. The colony consists of three type of bees. Employed bees associated with specific food sources, onlooker bees watching the dance of employed bees within the hive to choose a food source, and scout bees searching for food sources randomly. Onlookers and scouts are also called unemployed bees. Initially, all food source positions are discovered by scout bees. Thereafter, the nectar of food sources are exploited by employed bees and onlooker bees, and this continual exploitation will ultimately cause them to become exhausted. Then, the employed bee which was exploiting the exhausted food source becomes a scout bee in search of further food sources once again. In other words, the employed bee whose food source has been exhausted becomes a scout bee. In ABC, the position of a food source represents a possible solution to the problem and the nectar amount of a food source corresponds to the quality (fitness) of the associated solution. The number of employed bees is equal to the number of food sources (solutions) since each employed bee is associated with one and only one food source. \\

\noindent
Let $X=\{x_1,x_2,\ldots,x_N\}$ population of food sources, where $N$ is the population size and $x_i \in \R^D$.
$f: \R^{D}\to\R^1$ is the fitness function and $fitness_i=f(x_i)$ is the fitness value of $x_i$.\\
Every iteration employed bees search for new food sources using the following formula:
\begin{equation}\label{eqn_abc_neighborhood_search}
x_{new}=x_i(t)+\phi_i*(x_i(t)-x_{rand}(t))
\end{equation}
Where $\phi_i \in U(-1, 1)$, where $U$ stands for uniform distribution and $x_{rand}(t)$ is a random food source. \\
An onlooker bees go to search for new food source after the employed bees shared the food source information with them. If they go in the actual iteration depends on probability. This probability $P_i(t)$ is calculated in every iteration with the following way:
\begin{equation}\label{eqn_abc_prob}
P_i(t)=0.9*(fitness_i(t)/fitness_{best}(t))+0.1
\end{equation}
The better the $fittness_i(t)$ compared to $fittness_{best}(t)$ the higher the probability of an onlooker bee goes to find a new food source. The onlooker bee uses the same searching strategy as the employed bee.
The third type of bees are the scouts who search for a food source randomly. Employed bees whose solutions cannot be improved through a predetermined number of trials called "limit", their solutions are abandoned. Then, the scouts start to search for new solutions, absolutely randomly in the search space by the formula below. 
\begin{equation}\label{eqn_abc_random_search}
x_{i}=x^{min}+rand_{ij}*(x^{max}-x^{min})
\end{equation}
Where $rand_{i} \in U(0, 1)$, where $U$ stands for uniform distribution and $x^{min}$ and $x^{max}$ mean the min and max boundaries of the of the $D$ dimensional search space. \\


\section{Pseudo code}

\begin{algorithm}[H]
\caption{Artificial Bee Colony}
 
 \Begin{
 Set $N$: population size, $T$: number of iterations, $k$: number of bees, $limit$: number of unsuccessful trials of an employed bee \\
 Initialize random population of food sources $X=\{x_1,x_2,\ldots,x_N\}$, \\
 Calculate fitness values $fitness_i$ for $i \in
 \{1,2,...,N\}$\\
 \While{$t\leq T$ or Stopping criteria not met}{
  \For{$i \gets 1 \textrm{ to } k$}{
    Employed bee searches for new food source $x_{new}$ by Equation \ref{eqn_abc_neighborhood_search} \\
    Check search space \\
    Calculate fitness value $fitness_{new}$\\
    \If{$fitness_{new}<fitness_i$}{
      $x_i=x_{new}$ \\
      $fitness_i=fitness_{new}$ \\
      }    
    \Else{$bad\_trial_i = bad\_trial_i + 1$}
    }
   \For{$i \gets 1 \textrm{ to } k$}{
    \If{$rand_i<P_i(t)$}{
     Onlooker bee searches for new food source $x_{new}$ by Equation \ref{eqn_abc_neighborhood_search} \\
     Check search space \\
     Calculate fitness value $fitness_{new}$\\
     \If{$fitness_{new}<fitness_i$}{
      $x_i=x_{new}$ \\
      $fitness_i=fitness_{new}$ \\
      }
     }
     \Else{$bad\_trial_i = bad\_trial_i + 1$}
     }
   \For{$i \gets 1 \textrm{ to } k$}{
    \If{$bad\_trial_i>limit$}{
     Scout bee searches for new random food source $x_{new}$ by Equation \ref{eqn_abc_random_search}\\
     Calculate fitness value $fitness_{new}$\\
     $bad\_trial_i = 0$ \\
     }
     }  
    
    Check Stopping Criteria \\
    $t=t+1$
 }
 }
\end{algorithm}


\chapter{Particle Swarm Optimization (PSO)}
\section{Story}
\section{Pseudo code}
\section{Flowchart}

\chapter{Grey Wolf Optimization (GWO)}
\section{Story}

GWO \cite{gwo1} meta-heuristic approach was designed based on the group hierarchy and the hunting strategy of grey wolfs in nature. Grey wolfs normally live in a pack of 5-12 members with strong social hierarchy. The most dominant one, the leader is the alpha (in nature a pair of male and female). The alfa's responsibility to make decisions about hunting, sleeping, etc. The second most dominant is beta, who can be considered as an experienced, skilled member of the pack helping the alpha making decisions. The beta is subordinate to the alfa, but plays a discipliner role for the rest of the wolfes. The omega is the lowest ranked wolf, he has to submit to anyone in the pack. Wolfs who are not alfa, beta or omega are just called subordinates. They play the role of scouts, hunters, sentinels, caretakers. The social behaviour appears in hunting as well in a characteristic fashion. The GWO algorithm mimics the three stage hunting mechanism of grey wolfs: searching for prey, encircling prey and attacking. Four types of pack members can be found in the model. There are three dominant wolfes, alpha, beta and delta. They have the best fitness value. The rest of the wolfs are subordinates or omega who are guided by the three dominant wolfs. \\

\noindent
Let $X=\{x_1,x_2,\ldots,x_N\}$ population of wolfs, where $N$ is the population size and $x_i \in \R^D$.
$f: \R^{D}\to\R^1$ is the fitness function and $fitness_i=f(x_i)$ is the fitness value of $x_i$.\\
\noindent
Three parameters are needed to be updated: $a$, $A$ and $C$. \\
$a$ is decreasing from 2 to 0 by iteration linearly: \\
\begin{equation}\label{eqn_gwo_a_param}
a_{t+1}=2*(1-\frac{t}{T}) 
\end{equation}
\begin{equation}\label{eqn_gwo_A_param}
A=2*a*rand_{1}-a
\end{equation}
So $A$ is a random value in the interval $[-2a,2a]$. \\
\begin{equation}\label{eqn_gwo_C_param}
C=2*rand_{2}
\end{equation}
Hence $C$ is a random value in the interval $[0,2]$. \\
Where $rand_{i} \in U(0, 1)$, where $U$ stands for uniform distribution. \\ \\
Movement of wolfs determined by the leading wolfs and through coefficient vectors in the following way:
$D_{\alpha}=|C_1*x_{\alpha}(t)-x_i(t)|$, $D_{\beta}=|C_2*x_{\beta}(t)-x_i(t)|$, $D_{\delta}=|C_3*x_{\delta}(t)-x_i(t)|$ \\
$X_1=x_{\alpha}(t)-A_1*D_{\alpha}$, $X_2=x_{\beta}(t)-A_2*D_{\beta}$, $X_3=x_{\delta}(t)-A_3*D_{\delta}$ \\
\begin{equation}\label{eqn_gwo_step}
x_i(t+1)=\frac{X_1+X_2+X_3}{3}
\end{equation}
where $x_i(t)$ is the location of the ith wolf at iteration $t$, and $x_{\alpha}$ is the location of alpha. $x_{\alpha}: fitness_{\alpha}=\displaystyle \min_{i=1,\dots, N}f(x_i)$ (min because of minimization problem). $x_{\beta}$ has the second best fitness value, $x_{\delta}$ has the third one.\\ \\
Searching for prey (exploration) as other phases of hunting guided by the 3 dominant wolf. $|A|>1$ cases oblige the agent to diverge from the prey and search for better prey (solution). Encircling the prey is also controlled by coefficient vectors $A$ and $C$ and the location of alpha, beta, delta. Attacking of the prey (exploitation) phase is active when $|A|<1$. In this situation the force towards the prey is getting strong.\\

\section{Pseudo code}

\begin{algorithm}[H]
\caption{Grey Wolf Optimizer}
 
 \Begin{
 Set $N$: population size, $T$: number of iterations \\
 Initialize random population of wolfs $X=\{x_1,x_2,\ldots,x_N\}$, \\
 Calculate fitness values $fitness_i$ for $i \in
 \{1,2,...,N\}$\\
 \While{$t\leq T$ or Stopping criteria not met}{
  Decrease the value of $a$ by Equation \ref{eqn_gwo_a_param}\\
  Determine the three dominant wolfs $x_{alfa}, x_{beta}, x_{delta}$ \\
  \For{$i \gets 1 \textrm{ to } N$}{
  	  Update $A$ and $C$ parameters by Equation \ref{eqn_gwo_A_param} and \ref{eqn_gwo_C_param} \\
      Update location of wolf $x_i$ by Equation \ref{eqn_gwo_step} \\
      Check search space \\
      Calculate $fitness_i=f(x_i)$ \\
      \If{$fitness_i<fitness_{best}$}{
      $x_{best}=x_i$ \\
      $fitness_{best}=fitness_i$ \\
      }
    }
    Check Stopping Criteria \\
    $t=t+1$
 }
 }
\end{algorithm}

%\section{Flowchart}

\chapter{Whale Optimization Algorithm (WOA)}
\section{Story}

WOA \cite{woa1} was inspired by the bubble-net attack of humpback whales. Adult humpback whales have almost the size of a school bus and their main target preys are krills and small fish herds. Whales are very intelligent mammals. They can live and hunt alone and in groups as well. Humpback whales' special hunting method is called bubble-net feeding. This can be observed when small fish herds are close to the surface. The whale dive down first around 12 meters under the herd and then starst moving upward in a spiral shape by creating bubbles along the path to herd the krill herd together before the attack. This manouver was modelled as an optimization algorithm. The formalization is somewhat similar to Grey Wolf Optimizer's. But in this case the agents are drived in the exploitation phase by only one whale with the best fitness. And the exploration and exploitation

\noindent
Let $X=\{x_1,x_2,\ldots,x_N\}$ population of whales, where $N$ is the population size and $x_i \in \R^D$.
$f: \R^{D}\to\R^1$ is the fitness function and $fitness_i=f(x_i)$ is the fitness value of $x_i$.\\
\noindent
$b$ is a constant parameter. Generally $b=1$. It affects the spiral encircling move.
4 parameters are needed to be updated: $a$, $A$, $C$ and $l$. \\
$a$ is decreasing from 2 to 0 by iteration linearly: \\
\begin{equation}\label{eqn_woa_a_param}
a_{t+1}=2*(1-\frac{t}{T}) 
\end{equation}
\begin{equation}\label{eqn_woa_A_param}
A=2*a*rand_{1}-a
\end{equation}
So $A$ is a random value in the interval $[-2a,2a]$. \\
\begin{equation}\label{eqn_woa_C_param}
C=2*rand_{2}
\end{equation}
Hence $C$ is a random value in the interval $[0,2]$. \\
\begin{equation}\label{eqn_woa_l_param}
l=rand_{3}
\end{equation}
Where $rand_1 and rand_2 \in U(0, 1)$, $rand_2 \in U(-1, 1)$, and $U$ stands for uniform distribution. \\ \\
The exploration and exploitation phases are also controlled by a random mechanism. If $rand<p$ or $rand\geq p$ ($rand \in U(0, 1)$) the algorithm switches between strategies. $p$ is a fixed parameter, generally $p=0.5$.\\
The movement of whales in the population determined by the following way: \\
If $rand<p$ and $|A|<1$: \\
$D=|C*x_{best}(t)-x_i(t)|$ \\
\begin{equation}\label{eqn_woa_exploit_step}
x_i(t+1)=x_{best}(t)-A*D
\end{equation}
If $rand<p$ and $|A|>1$: \\
$D=|C*x_{rand}(t)-x_i(t)|$ \\
\begin{equation}\label{eqn_woa_explore_step}
x_i(t+1)=x_{rand}(t)-A*D
\end{equation}
Where $x_{rand}$ is a random member of the whale population. \\
If $rand\geq p$:
$D=|x_{best}(t)-x_i(t)|$ \\
\begin{equation}\label{eqn_woa_spiral_step}
x_i(t+1)=D*exp(bl)*cos(2\pi l)+x_{best}(t)
\end{equation}
where $x_i(t)$ is the location of the ith wolf at iteration $t$, and $x_{best}$ is the location of the whale with best fitness. $x_{best}: fitness_{best}=\displaystyle \min_{i=1,\dots, N}f(x_i)$ (min because of minimization problem). \\ \\
Searching for prey (exploration) as other phases of hunting guided by the 3 dominant wolf. $|A|>1$ cases oblige the agent to diverge from the prey and search for better prey (solution). Encircling the prey is also controlled by coefficient vectors $A$ and $C$ and the location of alpha, beta, delta. Attacking of the prey (exploitation) phase is active when $|A|<1$. In this situation the force towards the prey is getting strong.\\

\section{Pseudo code}

\begin{algorithm}[H]
\caption{Whale Optimization Algorithm}
 
 \Begin{
 Set $N$: population size, $T$: number of iterations \\
 Set $p$: strategy switch probability, $b$: constant of the spiral \\
 Initialize random population of whales $X=\{x_1,x_2,\ldots,x_N\}$, \\
 Calculate fitness values $fitness_i$ for $i \in
 \{1,2,...,N\}$\\
 \While{$t\leq T$ or Stopping criteria not met}{
  Decrease the value of $a$ by Equation \ref{eqn_woa_a_param}\\
  Determine the best whale $x_{best}$ \\
  \For{$i \gets 1 \textrm{ to } N$}{
  	  Update $A$, $C$ and $l$ parameters by Equation \ref{eqn_woa_A_param}, \ref{eqn_woa_C_param} and \ref{eqn_woa_l_param} \\
  	  \If{$rand<p$}{
  	  	\If{$|A|<1$}{
  	  	Update location of whale $x_i$ by Equation \ref{eqn_woa_exploit_step} \\
  	  	}
  	  	\Else{
  	  	Update location of whale $x_i$ by Equation \ref{eqn_woa_explore_step} \\
  	  	}
      }
      \Else{
      Update location of whale $x_i$ by Equation \ref{eqn_woa_spiral_step} \\
      }
      \If{$fitness_i<fitness_{best}$}{
      $x_{best}=x_i$ \\
      $fitness_{best}=fitness_i$ \\
      }
    }
    Check Stopping Criteria \\
    $t=t+1$
 }
 }
\end{algorithm}
%\section{Flowchart}

\chapter{Flower Pollination Algorithm (FPA)}
\section{Story}
\section{Pseudo code}
\section{Flowchart}

\chapter{Firefly Algorithm (FA)}
\section{Story}
\section{Pseudo code}
\section{Flowchart}

\chapter{Black Hole Algorithm (BHA)}
\section{Story}

BHA \cite{bha1, bha2} heuristic approach was introduced in 2012. The analogy is to create a random population of stars in the search space, the one with the best fitness value is considered as the black hole. The black hole gives a direction for every star's movement in all iterations. The stars are moving towards the black hole in a random way. After movement if the fitness value of a star is better than the fitness value of the black hole, then this star becomes the black hole. Furthermore another mechanism is involved to make a balance between exploration and exploitation, according to that if a star crosses the event horizon (defined distance from the black hole) then the black hole swallows it. Technically the star loose it's actual position and being redistributed randomly in the search space. Hence a new star is born to keep the population constant. \\

\noindent
Let $X=\{x_1,x_2,\ldots,x_N\}$ population of stars, where $N$ is the population size and $x_i \in \R^D$.
$f: \R^{D}\to\R^1$ is the fitness function and $fitness_i=f(x_i)$ is the fitness value of $x_i$.\\
\noindent
Movement of stars towards the black hole:
\begin{equation}\label{eqn_bha_step}
x_i(t+1)=x_i(t)+rand*(x_{BH}-x_i(t))
\end{equation}
where $x_i(t)$ is the location of the ith star at iteration $t$, and $x_{BH}$ is the black hole. $x_{BH}: fitness_{BH}=\displaystyle \min_{i=1,\dots, N}f(x_i)$ (min because of minimization problem). $rand \in U(0, 1)$, where $U$ stands for uniform distribution.\\
\noindent
Radius of the event horizon is calculated as follows:
\begin{equation}\label{eqn_bha_event_horizon}
Event Horizon=\frac{fitness_{BH}}{\sum\limits_{i=1}^N fitness_i}
\end{equation}



\section{Pseudo code}

\begin{algorithm}[H]
\caption{Black Hole Algorithm}
 
 \Begin{
 Set $N$: population size, $T$: number of iterations \\
 Initialize random population of stars $X=\{x_1,x_2,\ldots,x_N\}$, \\
 Calculate fitness values $fitness_i$ for $i \in
 \{1,2,...,N\}$ \\
 Determine the black hole $x_{BH}$, \\
 Calculate $Event Horizon$ by Equation \ref{eqn_bha_event_horizon} \\
 \While{$t\leq T$ or Stopping criteria not met}{
  \For{$i \gets 1 \textrm{ to } N$}{
      Update location of star $x_i$ by Equation \ref{eqn_bha_step} \\
      Check search space \\
      Calculate $fitness_i=f(x_i)$ \\
      \If{$fitness_i<fitness_{BH}$}{
      $x_{BH}=x_i$ \\
      $fitness_{BH}=fitness_i$ \\
      Calculate $Event Horizon$ by Equation \ref{eqn_bha_event_horizon}
      }
      \Else{
      \If{$\norm{x_{BH}-x_{i}}<Event Horizon$}{
      Reinitialize $x_i$ randomly within the search space
      }
      }
    } 
    Check Stopping Criteria \\
    $t=t+1$
 }
 }
\end{algorithm}

%\section{Flowchart}
%
%\begin{figure}[ht]
%\begin{tikzpicture}[font=\small,thick]

%%%%%% TUTORIAL %%%%%%%
% https://latexdraw.com/draw-flowcharts-latex-tutorial/
% https://www.overleaf.com/learn/latex/LaTeX_Graphics_using_TikZ%3A_A_Tutorial_for_Beginners_(Part_3)%E2%80%94Creating_Flowcharts
%https://texample.net/tikz/examples/flexible-flow-chart/
%https://texample.net/tikz/examples/tag/flowcharts/
%https://latexdraw.com/draw-flowcharts-latex-tutorial/
% https://www.google.com/search?q=metaheuristic+flow+chart&client=firefox-b-d&sxsrf=ALiCzsZvikf8bbFYQmi9ojJqxeTfVrzQmg:1652216663946&source=lnms&tbm=isch&sa=X&ved=2ahUKEwi7tOLa6tX3AhVnmIsKHc0vDCsQ_AUoAXoECAEQAw&biw=1704&bih=927&dpr=1#imgrc=iGtRMNvvKZcqIM


% Start block
%\node[draw,
%    rounded rectangle,
%    minimum width=2.5cm,
%    minimum height=1cm] (bha_start) {START};
%    
%% set population size and iteration number
%\node[rectangle, draw,
%    below=of bha_start,
%    minimum width=3.5cm,
%    minimum height=1cm
%] (bha_init1) {Set $N$: population size, $T$: number of iterations};
% 
%% Initialize population
%\node[rectangle, draw,
%    below=of bha_init1,
%    minimum width=3.5cm,
%    minimum height=1cm
%] (bha_init2) {Initialize population $X$};
%
%% calculate fitness
%\node[rectangle, draw,
%    below=of bha_init2,
%    minimum width=3.5cm,
%    minimum height=1cm
%] (bha_init3) {Calculate fitness values $fitness_i$, determine the black hole $x_{BH}$ and calculate $Event Horizon$};
%
%% iteration
%\node[rectangle, draw,
%    below=of bha_init3,
%    minimum width=3.5cm,
%    minimum height=1cm
%] (bha_iter) {For iter = 1 to $T$};
%
%% loop through population
%\node[rectangle, draw,
%    below=of bha_iter,
%    minimum width=3.5cm,
%    minimum height=1cm
%] (bha_pop) {For population member i = 1 to $N$};
%
%% random step
%\node[rectangle, draw,
%    below=of bha_pop,
%    minimum width=3.5cm,
%    minimum height=1cm
%] (bha_randstep) {Random step towards black hole $x_{BH}$};
%
%% loop through population
%\node[rectangle, draw,
%    below=of bha_iter,
%    minimum width=3.5cm,
%    minimum height=1cm
%] (bha_pop) {For population member i = 1 to $N$};
% 
%% fitness condition
%\node[draw,
%    diamond,
%    below=of bha_randstep,
%    minimum width=2.5cm,
%    inner sep=0] (bha_fitness_cond) {$fitness_i<fitness_{BH}$};
%    
%% new black hole
%\node[rectangle, draw,
%    below=of bha_fitness_cond,
%    minimum width=3.5cm,
%    minimum height=1cm
%] (bha_new_bh) {Set new black hole $x_{BH}=x_i$};
% 
%\node[draw,
%    diamond,
%    right=of bha_fitness_cond,
%    minimum width=2.5cm,
%    inner sep=0] (bha_dist_eh) { $\|x_{BH}-x_i\|<EventHorizon$};
%    
%% Start block
%\node[draw,
%    rounded rectangle,
%    minimum width=2.5cm,
%    minimum height=1cm] (bha_end) {END};
% 
% 
%% Arrows
%\draw[-latex,shorten >=0.2pt] (bha_start) edge (bha_init1)
%    (bha_init1) edge (bha_init2)
%    (bha_init2) edge (bha_init3)
%    (bha_init3) edge (bha_iter)
%    (bha_iter) edge (bha_pop)
%    (bha_pop) edge (bha_randstep)
%    (bha_randstep) edge (block3)
%    (block3) edge (block4);
% 
%\draw[-latex] (block4) -| (block5)
%    node[pos=0.25,fill=white,inner sep=0]{Yes};
% 
%\draw[-latex] (block4) -| (block6)
%    node[pos=0.25,fill=white,inner sep=0]{No};
% 
%\draw[-latex] (block5) edge node[pos=0.4,fill=white,inner sep=2pt]{No}(block7)
%    (block5) -| (block8)
%        node[pos=0.25,fill=white,inner sep=0]{Yes};
% 
%\draw[-latex] (block6) edge node[pos=0.4,fill=white,inner sep=2pt]{No}(block9)
%    (block6) -| (block10)
%        node[pos=0.25,fill=white,inner sep=0]{Yes};
% 
%\end{tikzpicture}
%
%\caption{Flowchart of Black Hole Algorithm (BHA)}
%\end{figure}



\begin{thebibliography}{9}

\bibitem{de1}
K. V. Price and O. Circle, 1996. \textit{Differential Evolution : A Fast and Simple Numerical Optimizer.} Biennial Conference of the North American Fuzzy Information Processing Society - NAFIPS, pp. 524–527, 1996.

\bibitem{es1}
Rechenberg I., 1971.\textit{Evolutionsstrategie – Optimierung technischer Systeme nach Prinzipien der biologischen Evolution (PhD thesis).} Frommann-Holzboog, 1973

\bibitem{es2}
Hans-Paul Schwefel, 1974.\textit{Numerische Optimierung von Computer-Modellen (PhD thesis).} Birkhäuser, 1977

\bibitem{cs1}
Yang X.-S., Deb S., 2009. \textit{Cuckoo search via Lévy flights.} World Congress on Nature \& Biologically Inspired Computing, 2009 \\
Link: \url{https://arxiv.org/abs/1003.1594v1}

\bibitem{abc1}
Karaboga D. 2005. \textit{An idea based on honey bee swarm for numerical optimizations.} Technical Report TR06, Erciyes University, Engineering Faculty, Computer Engineering Department, 2005

\bibitem{woa1}
Mirjalili S., Lewis A., 2015.\textit{The Whale Optimization Algorithm.} Elsevier, 2016: p. 51-67.

\bibitem{gwo1}
Mirjalili S., Mirjalili S., Lewis A., 2013.\textit{Grey Wolf Optimizer} Elsevier, 2014: p. 46-61.

\bibitem{bha1} 
Hatamlou, A., 2012. \textit{Black hole: A new heuristic optimization approach for data clustering.} Information sciences, 2012: p. 175-184. 

\bibitem{bha2} 
M. Farahmandian, A. Hatamlou, 2015. \textit{Solving optimization problems using black hole algorithm} Journal of Advanced Computer Science \& Technology, 2015: p. 68-74. \\
Link: \url{https://www.sciencepubco.com/index.php/JACST/article/view/4094/1621}

\end{thebibliography}


\end{document}